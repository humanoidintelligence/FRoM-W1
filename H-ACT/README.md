# H-ACT

**H-ACT** is the **action execution module** within the **FRoM-W1** framework. It converts the **action representation sequence** generated by **H-GPT** into executable motions on humanoid robots. This module contains three key components of **FRoM-W1**:

- **Retarget**  
  Converts H-GPT action representations into **SMPLX** motion sequences and further retargets them to various **humanoid robots** and **dexterous hands**. This also enables retargeting human motion datasets such as AMASS to multiple robot platforms.

- **Policy Training**  
  Trains action execution policies based on retargeted motion data (or other robot datasets).

- **Sim2sim & Sim2real**  
  Deploys trained policies to simulation or real robots, enabling sim2sim and sim2real execution.

# Motion Reconstruction & Retargeting

This part is responsible for reconstructing the **623-dimensional action representation** generated by H-GPT into **SMPLX motion sequences**, and retargeting them to the joint space of target humanoid robots and dexterous hands.

## ğŸ§© Environment Setup & Model Preparation

Enter the `H-ACT/retarget` directory and configure the retarget environment:

```bash
conda create -n retarget python=3.10
conda activate retarget
pip install -r requirements.txt
```

This module requires **SMPL** and **MANO** models. Before use, download the corresponding model files:

1. **Download MANO models**
   Visit the [MANO official website](https://mano.is.tue.mpg.de/) and download the model files
   (`MANO_LEFT.pkl`, `MANO_RIGHT.pkl`) into `models/mano`.

2. **Download SMPL models**
   Visit the [SMPL official website](https://smpl.is.tue.mpg.de/) and download
   (`SMPL_NEUTRAL.pkl`, `SMPL_MALE.pkl`, `SMPL_FEMALE.pkl`) into `models/smpl`.

Example directory structure:

```nginx
retarget
â”œâ”€â”€ models
â”‚   â”œâ”€â”€ mano
â”‚   â”‚   â”œâ”€â”€ MANO_LEFT.pkl
â”‚   â”‚   â””â”€â”€ MANO_RIGHT.pkl
â”‚   â””â”€â”€ smpl
â”‚       â”œâ”€â”€ SMPL_NEUTRAL.pkl
â”‚       â”œâ”€â”€ SMPL_MALE.pkl
â”‚       â””â”€â”€ SMPL_FEMALE.pkl
â”œâ”€â”€ ...
```

## ğŸ“ Data Preparation

Create the `data` directory inside `retarget` to store input and output data:

* `data/623`: stores the **623-dimensional action data** from H-GPT
* `data/smplx`: stores intermediate **SMPLX motion sequences**
* `data/output`: stores final robot & dexterous-hand joint sequences

Example structure:

```kotlin
retarget
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ 623
â”‚   â”‚   â”œâ”€â”€ data1.npy  # Output from H-GPT
â”‚   â”‚   â””â”€â”€ data2.npy
â”‚   â”œâ”€â”€ smplx          # Output SMPLX directory
â”‚   â”œâ”€â”€ output         # Output robot motion directory
â”œâ”€â”€ ...
```

## â–¶ï¸ Run (Retarget Execution)

Run the following command to retarget the action representations into robot-specific joint sequences:

```bash
python main.py
```

The module currently supports the following robots and dexterous hands:

* **Unitree H1**
* **Unitree G1**
* **Dex3**
* **InspireHand**

You can modify **lines 47â€“48** in `main.py` to select a target robot.

# Policy Training

In this stage, we train an action execution policy based on the motion data generated during the **Retarget** step (or any other robot motion dataset).  
Building upon **[Human2Humanoid](https://github.com/LeCAR-Lab/human2humanoid)**, we provide an action execution policy that supports **Unitree H1** and **Unitree G1**.  
Our deployment module also includes **pretrained policy models**â€”one for **Unitree G1** and one for **Unitree H1**â€”which can be used directly.

If you would like to train your own policy, please refer to our documentation:  
ğŸ‘‰ [Train](Human2Humanoid/README-zh.md)

Official Human2Humanoid repository:  
ğŸ‘‰ https://github.com/LeCAR-Lab/human2humanoid

In addition, if you want to experiment with other policy models for action execution, our deployment module also supports **[Beyondmimic](https://github.com/HybridRobotics/whole_body_tracking)**, **[TWIST](https://github.com/YanjieZe/TWIST)**, and more.  
Once you obtain your final policy model, proceed to the section on **[Simulation & Real-World Deployment](#ä»¿çœŸä¸çœŸæœºéƒ¨ç½²)** to execute your actions on real robots.

## Beyondmimic Policy Training

Beyondmimic requires input motion data in **CSV format**, so you must first convert the retargeted robot motion data into CSV.

Switch to the `H-ACT` directory and create the folder `data/beyondmimic` to store the results.  
Then run:

```bash
python scripts/pkl_2_csv.py
```

The converted motion files will appear in the `data/beyondmimic` directory.

Training instructions can be found in the official documentation:
ğŸ‘‰ [https://github.com/HybridRobotics/whole_body_tracking?tab=readme-ov-file#policy-training](https://github.com/HybridRobotics/whole_body_tracking?tab=readme-ov-file#policy-training)

## TWIST Policy Training

Refer to the official TWIST documentation:
ğŸ‘‰ [https://github.com/YanjieZe/TWIST](https://github.com/YanjieZe/TWIST)

# Simulation & Real-World Deployment

After training the desired policies, deployment can be carried out with our modolar simulation & real-robot deployment framework **[RoboJuDo](https://github.com/GDDG08/RoboJuDo)**.

We have an integrated version at [RoboJuDo](./RoboJuDo)

**RoboJuDo** supports:

* Sim2sim & sim2real deployment using Beyondmimic, Human2Humanoid, Twist, and more
* Pretrained policy models for quick real-robot deployment
* A unified, clean interface for integrating custom policy models with minimal effort

